{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a MovieLens Recommender System\n",
    "\n",
    "<img src=\"images/movielens.png\" width='25%' align='right'/>\n",
    "\n",
    "Want to know how Spotify, Amazon, and Netflix generate recommendations for their users? In this tutorial, we will explore two types of recommender systems: 1) collaborative filtering, and 2) content-based filtering. We will build our own recommendation system using the [MovieLens](https://movielens.org/home) dataset in Python.\n",
    "\n",
    "### What is MovieLens?\n",
    "\n",
    "MovieLens is a recommender system that was developed by GroupLens, a computer science research lab at the University of Minnesota. It recommends movies to its users based on their movie ratings. It is also a dataset that is widely used in research and teaching contexts. \n",
    "\n",
    "### Tutorial Outline\n",
    "\n",
    "This tutorial is broken down into 7 steps:\n",
    "\n",
    "1. Importing the dependnecies\n",
    "1. Loading the data\n",
    "1. Exploratory data analysis \n",
    "1. Data pre-processing\n",
    "1. Collaborative filtering using k-Nearest Neighbors\n",
    "1. Handling the cold-start problem with content-based filtering \n",
    "1. Dimensionality reduction with matrix factorization\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv(\"./DATA/ratings.csv\")\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv(\"./DATA/movies.csv\")\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_ratings = len(ratings)\n",
    "n_movies = ratings['movieId'].nunique()\n",
    "n_users = ratings['userId'].nunique()\n",
    "\n",
    "print(f\"Number of ratings: {n_ratings}\")\n",
    "print(f\"Number of unique movieId's: {n_movies}\")\n",
    "print(f\"Number of unique users: {n_users}\")\n",
    "print(f\"Average number of ratings per user: {round(n_ratings/n_users, 2)}\")\n",
    "print(f\"Average number of ratings per movie: {round(n_ratings/n_movies, 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the distribution of movie ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='rating',data=ratings,palette=\"viridis\")\n",
    "plt.title(\"Distribution of movie ratings\",fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Mean global rating: {round(ratings['rating'].mean(),2)}.\")\n",
    "mean_ratings = ratings.groupby('userId')['rating'].mean()\n",
    "print(f\"Mean rating per user: {round(mean_ratings.mean(),2)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which movies are most frequently rated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_ratings = ratings.merge(movies,on='movieId')\n",
    "movie_ratings['title'].value_counts()[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the highest and lowest rated movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_ratings = ratings.groupby('movieId')[['rating']].mean()\n",
    "lowest_rated = mean_ratings['rating'].idxmin()\n",
    "highest_rated = mean_ratings['rating'].idxmax()\n",
    "print(f\"The lowest rated movie is {movies[movies['movieId']==lowest_rated]}\\nThe highest rated movie is {movies[movies['movieId']==highest_rated]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many ratings does the `Highest rated movie` have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings[ratings['movieId']==highest_rated]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bayesian Average\n",
    "\n",
    "[Bayesian Average](https://en.wikipedia.org/wiki/Bayesian_average) is defined as:\n",
    "\n",
    "$r_{i} = \\frac{C \\times m + \\Sigma{\\text{reviews}}}{C+N}$\n",
    "\n",
    "where $C$ represents our confidence, $m$ represents our prior, and $N$ is the total number of reviews for movie $i$. In this case, our prior $m$ will be the average mean rating across all movies. By defintion, C represents \"the typical data set size\". Let's make $C$ be the average number of ratings for a given movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_stats = ratings.groupby('movieId')['rating'].agg(['count','mean'])\n",
    "movie_stats.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = movie_stats['count'].mean()\n",
    "m = movie_stats['mean'].mean()\n",
    "\n",
    "print(f\"Average number of ratings for a given movie: {C:.2f}\")\n",
    "print(f\"Average rating for a given movie: {m:.2f}\")\n",
    "\n",
    "def bayesian_avg(ratings):\n",
    "    bayesian_avg = (C*m+ratings.sum())/(C+ratings.count())\n",
    "    return round(bayesian_avg, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test our `bayesian_avg` function out on `Lamerica`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lamerica = pd.Series([5,5])\n",
    "bayesian_avg(lamerica)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayesian_avg_ratings = ratings.groupby('movieId')['rating'].agg(bayesian_avg).reset_index()\n",
    "bayesian_avg_ratings.columns = ['movieId', 'bayesian_avg']\n",
    "movie_stats = movie_stats.merge(bayesian_avg_ratings, on='movieId')\n",
    "movie_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_stats = movie_stats.merge(movies[['movieId', 'title']])\n",
    "movie_stats.sort_values('bayesian_avg_x', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Glimpse at Movie Genres\n",
    "\n",
    "The movies dataset needs to be cleaned in two ways:\n",
    "\n",
    "- `genres` is expressed as a string with a pipe `|` separating each genre. We will manipulate this string into a list, which will make it much easier to analyze.\n",
    "- `title` currently has (year) appended at the end. We will extract year from each title string and create a new column for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['genres'] = movies['genres'].apply(lambda x: x.split(\"|\"))\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many movie genres are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "genre_frequency = Counter(g for genres in movies['genres'] for g in genres)\n",
    "\n",
    "print(f\"There are {len(genre_frequency)} genres.\")\n",
    "\n",
    "genre_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The 5 most common genres: \\n\", genre_frequency.most_common(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top 5 genres are: `Drama`, `Comedy`, `Thriller`, `Action` and `Romance`.\n",
    "\n",
    "lets also visualize genres popularity with a barplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_frequency_df = pd.DataFrame([genre_frequency]).T.reset_index()\n",
    "genre_frequency_df.columns = ['genre', 'count']\n",
    "\n",
    "sns.barplot(x='genre', y='count', data=genre_frequency_df.sort_values(by='count', ascending=False))\n",
    "plt.xticks(rotation=90);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Data Pre-processing\n",
    "\n",
    "We are going to use a technique called colaborative filtering to generate recommendations for users. This technique is based on the premise that similar people like similar things. \n",
    "\n",
    "The first step is to transform our data into a user-item matrix, also known as a \"utility\" matrix. In this matrix, rows represent users and columns represent movies. The beauty of collaborative filtering is that it doesn't require any information about the users or the movies user to generate recommendations.\n",
    "\n",
    "<img src=\"./images/user_movie_matrix.png\" width=50%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `create_X()` function outputs a sparse matrix $X$ with four mapper dictionaries:\n",
    "\n",
    "- **user_mapper**: maps user id to user index\n",
    "- **movie_mapper**: maps movie id to movie index\n",
    "- **user_inv_mapper**: maps user index to user id\n",
    "- **movie_inv_mapper**: maps movie index to movie id\n",
    "\n",
    "We need these dictionaries because they map which row/column of the utility matrix corresponds to which user/movie id.\n",
    "\n",
    "Our $X$ (user-item) matrix is a [scipy.sparse.csr_matrix](https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.sparse.csr_matrix.html) which stores the data sparsely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "def create_X(df):\n",
    "    \"\"\"\n",
    "    Generates a sparse matrix from ratings dataframe.\n",
    "    \n",
    "    Args:\n",
    "        df: pandas dataframe containing 3 columns (userId, movieId, rating)\n",
    "    \n",
    "    Returns:\n",
    "        X: sparse matrix\n",
    "        user_mapper: dict that maps user id's to user indices\n",
    "        user_inv_mapper: dict that maps user indices to user id's\n",
    "        movie_mapper: dict that maps movie id's to movie indices\n",
    "        movie_inv_mapper: dict that maps movie indices to movie id's\n",
    "    \"\"\"\n",
    "    M = df['userId'].nunique()\n",
    "    N = df['movieId'].nunique()\n",
    "\n",
    "    user_mapper = dict(zip(np.unique(df[\"userId\"]), list(range(M))))\n",
    "    movie_mapper = dict(zip(np.unique(df[\"movieId\"]), list(range(N))))\n",
    "    \n",
    "    user_inv_mapper = dict(zip(list(range(M)), np.unique(df[\"userId\"])))\n",
    "    movie_inv_mapper = dict(zip(list(range(N)), np.unique(df[\"movieId\"])))\n",
    "    \n",
    "    user_index = [user_mapper[i] for i in df['userId']]\n",
    "    item_index = [movie_mapper[i] for i in df['movieId']]\n",
    "\n",
    "    X = csr_matrix((df[\"rating\"], (user_index,item_index)), shape=(M,N))\n",
    "    \n",
    "    return X, user_mapper, movie_mapper, user_inv_mapper, movie_inv_mapper\n",
    "\n",
    "X, user_mapper, movie_mapper, user_inv_mapper, movie_inv_mapper = create_X(ratings)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our `X` matrix contains 610 users and 9724 movies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating sparsity\n",
    "\n",
    "Here, we calculate sparsity by dividing the number of stored elements by total number of elements. The number of stored (non-empty) elements in our matrix ([nnz](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.nnz.html)) is equivalent to the number of ratings in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_total = X.shape[0]*X.shape[1]\n",
    "n_ratings = X.nnz\n",
    "sparsity = n_ratings/n_total\n",
    "print(f\"Matrix sparsity: {round(sparsity*100,2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`csr_matrix.nnz` counts the stored values in our sparse matrix. The rest of our cells are empty.\n",
    "\n",
    "The **cold start problem** is when there are new users and movies in our matrix that do not have any ratings. In our Movielens dataset, all users and movies have at least one rating but in general, it's useful to check which users and movies have few interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_ratings_per_user = X.getnnz(axis=1)\n",
    "len(n_ratings_per_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Most active user rated {n_ratings_per_user.max()} movies.\")\n",
    "print(f\"Least active user rated {n_ratings_per_user.min()} movies.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_ratings_per_movie = X.getnnz(axis=0)\n",
    "len(n_ratings_per_movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Most rated movie has {n_ratings_per_movie.max()} ratings.\")\n",
    "print(f\"Least rated movie has {n_ratings_per_movie.min()} ratings.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "plt.subplot(1,2,1)\n",
    "sns.kdeplot(n_ratings_per_user, shade=True)\n",
    "plt.xlim(0)\n",
    "plt.title(\"Number of Ratings Per User\", fontsize=14)\n",
    "plt.xlabel(\"number of ratings per user\")\n",
    "plt.ylabel(\"density\")\n",
    "plt.subplot(1,2,2)\n",
    "sns.kdeplot(n_ratings_per_movie, shade=True)\n",
    "plt.xlim(0)\n",
    "plt.title(\"Number of Ratings Per Movie\", fontsize=14)\n",
    "plt.xlabel(\"number of ratings per movie\")\n",
    "plt.ylabel(\"density\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
